{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just Enough Spark - a Jupyter Notebook\n",
    "\n",
    "You can execute each statement to generate the output, or choose any option in the \"Cell\" menu. Modify the statements to try new things. \n",
    "\n",
    "\n",
    "## An RDD is an immutable collection\n",
    "* Most methods set up the execution graph for spark\n",
    "* Action methods execute the graph\n",
    "* partial results can be cached for reuse\n",
    "\n",
    "*RDDs are construction with methods on the sparkContext (sc) object*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDDs can be created from files, Cassandra tables, Scala collections, and many other sources\n",
    "Let's first look at creating an an rdd from a Scala object.  We use the parallelize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val myrdd = sc.parallelize(Seq(4,5,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myrdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filter out the even numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val evenNumbers = myrdd.filter( x => x % 2 == 0)\n",
    "evenNumbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that nothing really happened - we set up the execution graph.  We'll use the *action* method *collect* to execute it and dump all of the results into an array.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evenNumbers.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine a table using CQL\n",
    "(Jupyter notebook feature)\n",
    "Use the %%Cql Magic to prefix your CQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%showschema music.tracks_by_album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%Cql select * from music.tracks_by_album limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating RDDs from Cassandra Tables\n",
    "* Can add a where clause to push down filter\n",
    "* Creates and RDD of CassandraRow objects\n",
    "* .as will map it to a case class or tuples for ease of use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val tracks = sc.cassandraTable(\"music\",\"tracks_by_album\")\n",
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracks.first\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the album and track in a tuple.  This is the new syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val albumTracks = sc.cassandraTable[(String,String)](\"music\",\n",
    "\"tracks_by_album\").select(\"album_title\",\"track_title\")\n",
    "albumTracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 10 rows as tuples ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "albumTracks.take(10) foreach println"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RDDs from Cassandra Tables and return an RDD of case class objects\n",
    ".as() will map the rdd to a case class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "case class Track(album_title: String,\n",
    "album_year:Int,\n",
    "track_number:Int,\n",
    "album_genre: Option[String],\n",
    "performer: Option[String],\n",
    "track_title: String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val tracks = sc.cassandraTable[Track](\"music\",\"tracks_by_album\")\n",
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracks take 5 foreach println"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other useful actions ...\n",
    "* first – same as take(1)(0)\n",
    "* collect – bring everything back to the caller as a scala array\n",
    "* saveToCassandra\n",
    "* count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracks.first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracks.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Typical Transformations\n",
    "filter, map, distinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show tracks from 1989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracks.filter(x => x.album_year == 1989).take(10).foreach(println)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This can also be accomplished with a .where function on the cassandraTable to push the work into Cassandra**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map the cassandra table to 2-tuples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracks.map(x =>(x.album_title, x.track_title)).\n",
    "   take(5).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine operations into a single graphe or even a single statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracks.filter(x => x.album_year == 1990).\n",
    "map(x => (x.album_title, x.track_title)).\n",
    "take(5).foreach(println)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair RDDs – Special operations on RDD of  2-Tuples\n",
    "* Think of each tuple as (Key,Value)\n",
    "* countByKey\n",
    "* groupByKey\n",
    "* reduceByKey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val albumTracks = tracks.map(t => (t.album_title, t.track_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many tracks in each album?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val trackTitles = albumTracks.countByKey\n",
    "trackTitles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why not sort the results descending? toList turns the map into a list of tuples and sort by the negative of the count\n",
    "\n",
    "## Top 10 List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "albumTracks.countByKey.toList.sortBy( t => -t._2 ) take 10 foreach println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracks.filter(_.album_title == \"Greatest Hits\").collect foreach println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var x:Option[Int] = Some(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.orElse(Some(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracks.filter(_.album_title == \"Greatest Hits\").saveAsTextFile(\"cfs:///tmp/tracks2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark-DSE Cluster",
   "language": "scala",
   "name": "spark-dse-cluster"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
